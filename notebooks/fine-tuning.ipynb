{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Device:\", device)\n",
    "\n",
    "block_size = 128\n",
    "batch_size = 64\n",
    "max_iters = 1000\n",
    "learning_rate = 3e-4\n",
    "eval_iters = 100\n",
    "n_embd = 384\n",
    "n_layer = 8\n",
    "n_head = 8\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   5572 non-null   object\n",
      " 1   text    5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n",
      "None\n",
      "label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/raw/SMSSpamCollection.tsv\", sep=\"\\t\", header=None, names=[\"label\", \"text\"])\n",
    "print(df.info())\n",
    "print(df[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_balanced_dataset(df):\n",
    "    num_spam = df[df[\"label\"] == \"spam\"].shape[0]\n",
    "    # print(num_spam)\n",
    "    ham_subset = df[df[\"label\"] == \"ham\"].sample(num_spam, random_state=42)\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"label\"] == \"spam\"]])\n",
    "    return balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3714</th>\n",
       "      <td>0</td>\n",
       "      <td>If i not meeting ü all rite then i'll go home ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>0</td>\n",
       "      <td>I.ll always be there, even if its just in spir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>0</td>\n",
       "      <td>Sorry that took so long, omw now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324</th>\n",
       "      <td>0</td>\n",
       "      <td>I thk 50 shd be ok he said plus minus 10.. Did...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3184</th>\n",
       "      <td>0</td>\n",
       "      <td>Dunno i juz askin cos i got a card got 20% off...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "3714      0  If i not meeting ü all rite then i'll go home ...\n",
       "1311      0  I.ll always be there, even if its just in spir...\n",
       "548       0                   Sorry that took so long, omw now\n",
       "1324      0  I thk 50 shd be ok he said plus minus 10.. Did...\n",
       "3184      0  Dunno i juz askin cos i got a card got 20% off..."
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df[\"label\"] = balanced_df[\"label\"].map({\"ham\": 0, \"spam\": 1})\n",
    "balanced_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(df, split=0.8):\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "    df_train = df[:int(split*len(df))]\n",
    "    df_val = df[int(split*len(df)):]\n",
    "    return df_train, df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                               text\n",
      "0      0                         K still are you loving me.\n",
      "1      0            I think we're going to finn's now, come\n",
      "2      1  Reminder: You have not downloaded the content ...\n",
      "3      1  Got what it takes 2 take part in the WRC Rally...\n",
      "4      1  Shop till u Drop, IS IT YOU, either 10K, 5K, £...\n",
      "      label                                               text\n",
      "1195      1  Ur cash-balance is currently 500 pounds - to m...\n",
      "1196      1  Thanks for your ringtone order, reference numb...\n",
      "1197      0  I absolutely LOVE South Park! I only recently ...\n",
      "1198      1  1st wk FREE! Gr8 tones str8 2 u each wk. Txt N...\n",
      "1199      0         Can i get your opinion on something first?\n"
     ]
    }
   ],
   "source": [
    "train_df, validation_df = random_split(balanced_df)\n",
    "print(train_df.head())\n",
    "print(validation_df.head())\n",
    "train_df.to_csv(\"data/processed/fine_tune_train.csv\", index=None)\n",
    "validation_df.to_csv(\"data/processed/fine_tune_validation.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model parameters...\n",
      "loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "chars = \"\"\n",
    "\n",
    "with open('data/raw/OpenWebText/vocab.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "    chars = sorted(list(set(text)))\n",
    "\n",
    "vocab_size = len(chars)\n",
    "\n",
    "\n",
    "string_to_int = { ch:i for i, ch in enumerate(chars) }\n",
    "int_to_string = { i:ch for i, ch in enumerate(chars) }\n",
    "\n",
    "encode = lambda s: [string_to_int[c] for c in s]\n",
    "decode = lambda l: ''.join([int_to_string[i] for i in l])\n",
    "\n",
    "class Head(nn.Module):\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x)   # (B, T, hs)\n",
    "        q = self.query(x) # (B, T, hs)\n",
    "        wei = q @ k.transpose(-2, -1) * k.shape[-1]**-0.5 # (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        v = self.value(x)\n",
    "        out = wei @ v\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedForward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.sa(x)\n",
    "        x = self.ln1(x + y)\n",
    "        y = self.ffwd(x)\n",
    "        x = self.ln2(x + y)\n",
    "        return x\n",
    "\n",
    "\n",
    "class GPTLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd)\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "        self.classification_head = nn.Linear(n_embd, 1)  # New classification head\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0, std=0.02)\n",
    "        elif isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "\n",
    "    def forward(self, index, targets=None, classify=False):\n",
    "        B, T = index.shape\n",
    "\n",
    "        tok_emb = self.token_embedding_table(index)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device))\n",
    "        x = tok_emb + pos_emb\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln_f(x)\n",
    "        \n",
    "        if classify:\n",
    "            # For classification, we'll use the mean of all token representations\n",
    "            x_mean = x.mean(dim=1)\n",
    "            logits = self.classification_head(x_mean).squeeze(-1)\n",
    "            if targets is not None:\n",
    "                loss = F.binary_cross_entropy_with_logits(logits, targets.float())\n",
    "            else:\n",
    "                loss = None\n",
    "        else:\n",
    "            logits = self.lm_head(x)\n",
    "            if targets is not None:\n",
    "                B, T, C = logits.shape\n",
    "                logits = logits.view(B*T, C)\n",
    "                targets = targets.view(B*T)\n",
    "                loss = F.cross_entropy(logits, targets)\n",
    "            else:\n",
    "                loss = None\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def classify(self, index):\n",
    "        # Method for getting classification probabilities\n",
    "        logits, _ = self.forward(index, classify=True)\n",
    "        return torch.sigmoid(logits)\n",
    "    \n",
    "    def generate(self, index, max_new_tokens):\n",
    "        # index is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            index_cond = index[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self.forward(index_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            index_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            index = torch.cat((index, index_next), dim=1) # (B, T+1)\n",
    "        return index\n",
    "\n",
    "model = GPTLanguageModel(vocab_size)\n",
    "print('loading model parameters...')\n",
    "with open('data/models/model-04-reddit_text.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "print('loaded successfully!')\n",
    "model.classification_head = nn.Linear(n_embd, 1)\n",
    "\n",
    "model = model.to(device)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SMSDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.data.iloc[index]['text']\n",
    "        label = self.data.iloc[index]['label']\n",
    "        \n",
    "        encoded = self.tokenizer(text)\n",
    "        if len(encoded) > self.max_len:\n",
    "            encoded = encoded[:self.max_len]\n",
    "        else:\n",
    "            encoded = encoded + [0] * (self.max_len - len(encoded))  # Padding\n",
    "        \n",
    "        return {\n",
    "            'input_ids': torch.tensor(encoded, dtype=torch.long),\n",
    "            'label': torch.tensor(label, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "# Assuming you have train_df and validation_df from your previous data preparation\n",
    "train_dataset = SMSDataset(train_df, encode, block_size)\n",
    "val_dataset = SMSDataset(validation_df, encode, block_size)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits, loss = model(input_ids, labels, classify=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            logits, loss = model(input_ids, labels, classify=True)\n",
    "            preds = torch.sigmoid(logits) > 0.5\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    accuracy = (np.array(all_preds) == np.array(all_labels)).mean()\n",
    "    return total_loss / len(dataloader), accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Train Loss: 0.3114\n",
      "Val Loss: 0.2030, Val Accuracy: 0.9264\n",
      "\n",
      "Epoch 2/5\n",
      "Train Loss: 0.1548\n",
      "Val Loss: 0.1434, Val Accuracy: 0.9498\n",
      "\n",
      "Epoch 3/5\n",
      "Train Loss: 0.0962\n",
      "Val Loss: 0.1603, Val Accuracy: 0.9565\n",
      "\n",
      "Epoch 4/5\n",
      "Train Loss: 0.0371\n",
      "Val Loss: 0.1845, Val Accuracy: 0.9465\n",
      "\n",
      "Epoch 5/5\n",
      "Train Loss: 0.0149\n",
      "Val Loss: 0.2503, Val Accuracy: 0.9365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, device)\n",
    "    val_loss, val_accuracy = evaluate(model, val_loader, device)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model_spam.pth')\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_112924/1983867729.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_model_spam.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of text 1 being spam: 0.5386\n",
      "Probability of text 2 being spam: 0.0254\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('best_model_spam.pth'))\n",
    "model.eval()\n",
    "\n",
    "def predict(text):\n",
    "    encoded = encode(text)\n",
    "    if len(encoded) > block_size:\n",
    "        encoded = encoded[:block_size]\n",
    "    else:\n",
    "        encoded = encoded + [0] * (block_size - len(encoded))\n",
    "    encoded = torch.tensor([encoded], dtype=torch.long).to(device)\n",
    "    with torch.no_grad():\n",
    "        prob = model.classify(encoded)\n",
    "    return prob.item()\n",
    "\n",
    "text1 = \"Buy my course for 50% off\"\n",
    "text2 = \"Hi pls come 2 games volrent\"\n",
    "prob1 = predict(text1)\n",
    "prob2 = predict(text2)\n",
    "print(f\"Probability of text 1 being spam: {prob1:.4f}\")\n",
    "print(f\"Probability of text 2 being spam: {prob2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
