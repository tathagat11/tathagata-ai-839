{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is training bigram language model with the short frankenstein dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/raw/frankenstein.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " evil\n",
      "forebodings. I arrived here yesterday, and my first task is to assure\n",
      "my dear sister of my welfare and increasing confidence in the success\n",
      "of my undertaking.\n",
      "\n",
      "I am already far north of London, \n"
     ]
    }
   ],
   "source": [
    "print(text[200:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(set(text))\n",
    "vocab_size = len(chars)\n",
    "learning_rate = 3e-4\n",
    "max_iter = 2000\n",
    "# print(chars)\n",
    "# print(len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_to_int = { ch:i for i, ch in enumerate(chars) }\n",
    "int_to_string = { i:ch for i, ch in enumerate(chars) }\n",
    "\n",
    "encode = lambda s: [string_to_int[c] for c in s]\n",
    "decode = lambda l: ''.join([int_to_string[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([32, 51, 66, 66, 51, 64,  1,  9,  0,  0, 46, 39, 61,  1, 33, 64, 65,  7,\n",
      "         1, 38, 47, 68, 55, 58, 58, 51,  5,  1, 25, 60, 53, 58, 47, 60, 50,  7,\n",
      "        46,  0,  0,  0, 38, 66,  7,  1, 36, 51, 66, 51, 64, 65, 48, 67, 64, 53,\n",
      "        54,  5,  1, 24, 51, 49,  7,  1,  9,  9, 66, 54,  5,  1,  9, 15, 78,  7,\n",
      "         0,  0,  0, 43, 61, 67,  1, 69, 55, 58, 58,  1, 64, 51, 56, 61, 55, 49,\n",
      "        51,  1, 66, 61,  1, 54, 51, 47, 64,  1])\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "n = int(0.8 * len(data))\n",
    "train_data = data[:n]\n",
    "test_data = data[n:]\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "block_size = 8\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else test_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "\n",
    "    # print(ix)\n",
    "\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    # print(\"x:\", x)\n",
    "    # print(\"y:\", y)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'test']:\n",
    "        losses = torch.zeros(1000)\n",
    "        for k in range(1000):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "    \n",
    "    def forward(self, idx, targets=None):\n",
    "        logits = self.token_embedding_table(idx)\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self.forward(idx)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A7“‘JBèaFrCYx1è(s[Oæ“rOtHè(dKG3n,0kiR;CK2F”K2”]yn1Jh6MJ)v:LUT?fn[LU2tdu?A[)d3pObaES[xhfiF1-\n",
      "plwG,_‘NPeôrcséhlæz88i03n;BVhlw:S!Vs’?u5SMpc3!h-jW7HA4W(uPeo[Vp5CnBiwjFb1aRN_mBCR2”aKAvei‘SmOeoVn!gVdqé k4lCg5qé01Oz[Dp]n_fa_i_—YWVy6YB5bxO57pH(2tIéuk,abSyd.y3èk2—PuLê’A-5-LnOqM2_‘g7GMP5èFy9y\n",
      "xOsn3pjoôsq7:bYTlfê’389!h(u]fôl,èOoleC)—;GT!iP‘NLTP58qzOsqô0kU —qDUSfu\n",
      "bGEôu—”2Yvb?TuqKDA[bx”uwaWCwCBôssuiEJ[Oæ2hM9pv4KlfuLUJz8a9OEn8ccéCL?i_]j(GLjJCangUa5C;2OzOvrr8xKWæD“r:\n",
      "gmx08qôsmGMKd_bh6jvRuw\n",
      ";Cawybxrêè5b4W1v1y6\n"
     ]
    }
   ],
   "source": [
    "model = BigramLanguageModel(vocab_size=vocab_size)\n",
    "\n",
    "m = model.to(device)\n",
    "\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "\n",
    "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
    "\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 5.0014, test loss 5.0008\n",
      "step 500: train loss 4.8624, test loss 4.8775\n",
      "step 1000: train loss 4.7327, test loss 4.7435\n",
      "step 1500: train loss 4.6089, test loss 4.6009\n",
      "4.403591156005859\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=learning_rate)\n",
    "\n",
    "for i in range(max_iter):\n",
    "    if i % 500 == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {i}: train loss {losses['train']:.4f}, test loss {losses['test']:.4f}\")\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    logits, loss = model.forward(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I7é]”a5h(,4u—fu?2OA_GTxV]M90hf-KmBYWSdpjwly”vh(IkeP1n4)mBVY—7[_mKRN‘Y)Drbur]\n",
      "V.é0e4w“fô-5JCC,vuSoeEmBè’TA[YM’qY0MBV‘‘ét.S!unrdMRN:S4DG_HIW3VKK4é5[æFeY4æg!Moc[s,7gn[ks?6(hè—F”Vpf“æCMRjê_Hn—é5,nrj,;K!æ89’akè(—rEaFqS”3ês[V;l 6D[”:U_mKd3!m,xcèPLRL22)ju9.? p’KHv9ki?pY3sM2M2_kdKx‘MB.i”R;w!W\n",
      " yvH]-Lê2OnJhT,mTPx1è7tIKxBsu P:—é5h(“r:7_K;Vôs[V]yu?CwThNu.1P1-Kæ3lTanENghoATj8H48(u5TPSPOYvôA7i-C“VkUPthlô0hIKô!BeNkbAl!AvFIfonf1DIYês3Rc29WIT5CMvp]-T]AuR“c3“ukègub7N3A7é5ôswyS_ieC(IYDrdi-,j1F2ôWV]ôsLci:n,’]M CSF\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "\n",
    "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
    "\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2614, 0.8201, 0.6108, 0.6099, 0.9468, 0.2027, 0.4201, 0.3709, 0.0372,\n",
      "         0.7046],\n",
      "        [0.9665, 0.2480, 0.5409, 0.6666, 0.4512, 0.7444, 0.9035, 0.5925, 0.6643,\n",
      "         0.7800],\n",
      "        [0.3299, 0.1288, 0.8896, 0.4882, 0.9520, 0.6204, 0.3664, 0.4424, 0.9795,\n",
      "         0.8607],\n",
      "        [0.5628, 0.9545, 0.7894, 0.2103, 0.4152, 0.5301, 0.5751, 0.4200, 0.7714,\n",
      "         0.2632],\n",
      "        [0.6302, 0.4421, 0.2696, 0.3380, 0.4930, 0.8043, 0.8058, 0.9885, 0.4748,\n",
      "         0.0607],\n",
      "        [0.2415, 0.7352, 0.2297, 0.2505, 0.6610, 0.9001, 0.9442, 0.8623, 0.1589,\n",
      "         0.5244],\n",
      "        [0.0620, 0.8471, 0.8327, 0.2066, 0.4711, 0.6449, 0.3586, 0.8949, 0.8456,\n",
      "         0.1658],\n",
      "        [0.6092, 0.8822, 0.7033, 0.9077, 0.4298, 0.2365, 0.2287, 0.0269, 0.2663,\n",
      "         0.3500],\n",
      "        [0.6886, 0.4005, 0.1077, 0.4031, 0.3640, 0.7288, 0.4086, 0.9565, 0.7075,\n",
      "         0.0115],\n",
      "        [0.9521, 0.7675, 0.5094, 0.9617, 0.7222, 0.4640, 0.5774, 0.6737, 0.0786,\n",
      "         0.6971],\n",
      "        [0.0145, 0.5525, 0.4216, 0.4412, 0.1346, 0.3886, 0.6139, 0.9176, 0.1882,\n",
      "         0.4281],\n",
      "        [0.9882, 0.0267, 0.0028, 0.6263, 0.6715, 0.3861, 0.3210, 0.8442, 0.2043,\n",
      "         0.2400],\n",
      "        [0.4022, 0.1183, 0.9070, 0.3921, 0.7601, 0.2251, 0.0039, 0.0900, 0.2034,\n",
      "         0.5647],\n",
      "        [0.4545, 0.8848, 0.4690, 0.8383, 0.4106, 0.9418, 0.5233, 0.7808, 0.8620,\n",
      "         0.1518],\n",
      "        [0.4566, 0.7464, 0.0539, 0.2007, 0.8232, 0.3527, 0.8067, 0.6979, 0.7776,\n",
      "         0.0693],\n",
      "        [0.1373, 0.9049, 0.5475, 0.0534, 0.3741, 0.3859, 0.6157, 0.4188, 0.9159,\n",
      "         0.5754],\n",
      "        [0.4367, 0.1806, 0.2815, 0.9547, 0.3035, 0.9296, 0.8354, 0.9853, 0.8114,\n",
      "         0.6633],\n",
      "        [0.6276, 0.7151, 0.6326, 0.2389, 0.3887, 0.6800, 0.4947, 0.5081, 0.7000,\n",
      "         0.8470],\n",
      "        [0.5874, 0.7437, 0.7353, 0.3863, 0.8042, 0.4387, 0.1661, 0.1795, 0.0371,\n",
      "         0.2313],\n",
      "        [0.3332, 0.2773, 0.7433, 0.0528, 0.3711, 0.8268, 0.9480, 0.4506, 0.0906,\n",
      "         0.5977],\n",
      "        [0.1912, 0.2981, 0.1634, 0.1020, 0.9559, 0.6807, 0.0715, 0.8960, 0.4630,\n",
      "         0.9403],\n",
      "        [0.5551, 0.6604, 0.7829, 0.6835, 0.2268, 0.0391, 0.8695, 0.1282, 0.4407,\n",
      "         0.4425],\n",
      "        [0.8604, 0.7126, 0.5531, 0.4315, 0.0977, 0.5593, 0.4827, 0.7236, 0.6011,\n",
      "         0.7569],\n",
      "        [0.2902, 0.2115, 0.8958, 0.4117, 0.0603, 0.9312, 0.3954, 0.2802, 0.2563,\n",
      "         0.3281],\n",
      "        [0.1385, 0.4981, 0.8516, 0.0203, 0.5629, 0.4733, 0.3860, 0.0639, 0.3124,\n",
      "         0.2703],\n",
      "        [0.4029, 0.7695, 0.2567, 0.9885, 0.9687, 0.4298, 0.1677, 0.4971, 0.7210,\n",
      "         0.2788],\n",
      "        [0.7312, 0.0708, 0.5132, 0.9377, 0.9808, 0.3297, 0.3659, 0.7632, 0.7689,\n",
      "         0.4520],\n",
      "        [0.2499, 0.0017, 0.6394, 0.2072, 0.3822, 0.6934, 0.3330, 0.9298, 0.9038,\n",
      "         0.4024],\n",
      "        [0.3590, 0.8285, 0.4588, 0.6476, 0.3839, 0.1534, 0.5775, 0.5104, 0.2713,\n",
      "         0.2395],\n",
      "        [0.6365, 0.4371, 0.9795, 0.4058, 0.7780, 0.4691, 0.9047, 0.9912, 0.2096,\n",
      "         0.5268],\n",
      "        [0.2486, 0.5238, 0.0868, 0.6981, 0.2900, 0.8725, 0.3408, 0.2840, 0.4731,\n",
      "         0.3387],\n",
      "        [0.9158, 0.6502, 0.6047, 0.0821, 0.3586, 0.4873, 0.2891, 0.4173, 0.0400,\n",
      "         0.2478]])\n",
      "tensor([0.7046, 0.7800, 0.8607, 0.2632, 0.0607, 0.5244, 0.1658, 0.3500, 0.0115,\n",
      "        0.6971, 0.4281, 0.2400, 0.5647, 0.1518, 0.0693, 0.5754, 0.6633, 0.8470,\n",
      "        0.2313, 0.5977, 0.9403, 0.4425, 0.7569, 0.3281, 0.2703, 0.2788, 0.4520,\n",
      "        0.4024, 0.2395, 0.5268, 0.3387, 0.2478])\n"
     ]
    }
   ],
   "source": [
    "input = torch.rand((4, 8, 10))\n",
    "B, T, C = input.shape\n",
    "output = input.view(B*T, C)\n",
    "print(output)\n",
    "print(output[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([-0.05], dtype=torch.float32)\n",
    "Y = F.relu(x)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4875])\n"
     ]
    }
   ],
   "source": [
    "Y = F.sigmoid(x)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0500])\n"
     ]
    }
   ],
   "source": [
    "Y = F.tanh(x)\n",
    "print(Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
