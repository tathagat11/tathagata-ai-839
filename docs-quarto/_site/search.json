[
  {
    "objectID": "project_card.html",
    "href": "project_card.html",
    "title": "Project Card",
    "section": "",
    "text": "Financial institutions face significant challenges in assessing credit risk for loan applications. Traditional credit scoring methods often miss nuanced patterns and can be biased against certain demographic groups. This leads to both missed opportunities for good borrowers being denied and increased risk from bad loans being approved. In today’s competitive banking environment, institutions need more sophisticated ways to evaluate credit applications while maintaining regulatory compliance and fairness.\n\n\n\nBanks need to accurately assess the creditworthiness of loan applicants to minimize default risk while maximizing approved loans to qualified borrowers. Currently, credit officers spend significant time manually reviewing applications and may make inconsistent decisions based on limited information. This results in both lost revenue from good applications being rejected and losses from bad loans being approved.\n\n\n\nPrimary customers are:\n\nCredit risk officers at medium to large retail banks\nLoan application processing teams\nBanking compliance officers responsible for fair lending practices\nFinancial institutions serving diverse demographic populations\n\n\n\n\n\nReduce loan default rates through more accurate risk assessment\nIncrease loan approval rates for qualified borrowers\nReduce application processing time\nImprove consistency and fairness in lending decisions\nEnable regulatory compliance through transparent decision-making\n\n\n\n\nCredit officers will receive a streamlined workflow where they: 1. Input standard loan application data into a familiar interface 2. Receive an immediate risk assessment score with key contributing factors 3. View detailed explanations of risk factors in an intuitive dashboard 4. Override recommendations with documented justification when needed 5. Generate standardized reports for audit and compliance purposes\n\n\n\n\nDeploy MVP risk assessment system to pilot branch by Q4 2024\nAchieve 90% user adoption among credit officers within 6 months of launch\nDemonstrate statistical fairness across demographic groups within the next quarter after launch\nObtain regulatory approval by mid 2025\n\n\n\n\n\nData Privacy & Security\n\nHandling sensitive financial and personal information\nEnsuring compliance with data protection regulations\nSecuring data transfer between systems\n\nUser Adoption\n\nResistance from experienced credit officers\nTraining requirements for new system\nIntegration with existing workflows\n\nRegulatory Compliance\n\nMeeting fair lending requirements\nProviding required transparency in decisions\nMaintaining audit trails",
    "crumbs": [
      "Read The Docs",
      "Cards",
      "Project Card"
    ]
  },
  {
    "objectID": "project_card.html#background",
    "href": "project_card.html#background",
    "title": "Project Card",
    "section": "",
    "text": "Financial institutions face significant challenges in assessing credit risk for loan applications. Traditional credit scoring methods often miss nuanced patterns and can be biased against certain demographic groups. This leads to both missed opportunities for good borrowers being denied and increased risk from bad loans being approved. In today’s competitive banking environment, institutions need more sophisticated ways to evaluate credit applications while maintaining regulatory compliance and fairness.",
    "crumbs": [
      "Read The Docs",
      "Cards",
      "Project Card"
    ]
  },
  {
    "objectID": "project_card.html#problem",
    "href": "project_card.html#problem",
    "title": "Project Card",
    "section": "",
    "text": "Banks need to accurately assess the creditworthiness of loan applicants to minimize default risk while maximizing approved loans to qualified borrowers. Currently, credit officers spend significant time manually reviewing applications and may make inconsistent decisions based on limited information. This results in both lost revenue from good applications being rejected and losses from bad loans being approved.",
    "crumbs": [
      "Read The Docs",
      "Cards",
      "Project Card"
    ]
  },
  {
    "objectID": "project_card.html#customer",
    "href": "project_card.html#customer",
    "title": "Project Card",
    "section": "",
    "text": "Primary customers are:\n\nCredit risk officers at medium to large retail banks\nLoan application processing teams\nBanking compliance officers responsible for fair lending practices\nFinancial institutions serving diverse demographic populations",
    "crumbs": [
      "Read The Docs",
      "Cards",
      "Project Card"
    ]
  },
  {
    "objectID": "project_card.html#value-proposition",
    "href": "project_card.html#value-proposition",
    "title": "Project Card",
    "section": "",
    "text": "Reduce loan default rates through more accurate risk assessment\nIncrease loan approval rates for qualified borrowers\nReduce application processing time\nImprove consistency and fairness in lending decisions\nEnable regulatory compliance through transparent decision-making",
    "crumbs": [
      "Read The Docs",
      "Cards",
      "Project Card"
    ]
  },
  {
    "objectID": "project_card.html#product",
    "href": "project_card.html#product",
    "title": "Project Card",
    "section": "",
    "text": "Credit officers will receive a streamlined workflow where they: 1. Input standard loan application data into a familiar interface 2. Receive an immediate risk assessment score with key contributing factors 3. View detailed explanations of risk factors in an intuitive dashboard 4. Override recommendations with documented justification when needed 5. Generate standardized reports for audit and compliance purposes",
    "crumbs": [
      "Read The Docs",
      "Cards",
      "Project Card"
    ]
  },
  {
    "objectID": "project_card.html#objectives",
    "href": "project_card.html#objectives",
    "title": "Project Card",
    "section": "",
    "text": "Deploy MVP risk assessment system to pilot branch by Q4 2024\nAchieve 90% user adoption among credit officers within 6 months of launch\nDemonstrate statistical fairness across demographic groups within the next quarter after launch\nObtain regulatory approval by mid 2025",
    "crumbs": [
      "Read The Docs",
      "Cards",
      "Project Card"
    ]
  },
  {
    "objectID": "project_card.html#risks-challenges",
    "href": "project_card.html#risks-challenges",
    "title": "Project Card",
    "section": "",
    "text": "Data Privacy & Security\n\nHandling sensitive financial and personal information\nEnsuring compliance with data protection regulations\nSecuring data transfer between systems\n\nUser Adoption\n\nResistance from experienced credit officers\nTraining requirements for new system\nIntegration with existing workflows\n\nRegulatory Compliance\n\nMeeting fair lending requirements\nProviding required transparency in decisions\nMaintaining audit trails",
    "crumbs": [
      "Read The Docs",
      "Cards",
      "Project Card"
    ]
  },
  {
    "objectID": "project_card.html#task",
    "href": "project_card.html#task",
    "title": "Project Card",
    "section": "Task",
    "text": "Task\nThis is a binary classification problem predicting credit risk based on the provided dataset (dataset_id_96.csv). According to the code and data samples, we need to predict ‘y’ (True/False) indicating whether a loan application represents a good or bad credit risk.",
    "crumbs": [
      "Read The Docs",
      "Cards",
      "Project Card"
    ]
  },
  {
    "objectID": "project_card.html#metrics",
    "href": "project_card.html#metrics",
    "title": "Project Card",
    "section": "Metrics",
    "text": "Metrics\n\nPrimary: F1 score (currently being tracked in evaluate_model function)\nSupporting metrics:\n\nAccuracy\nPrecision\nRecall\nTarget drift score (monitored via Evidently)",
    "crumbs": [
      "Read The Docs",
      "Cards",
      "Project Card"
    ]
  },
  {
    "objectID": "project_card.html#evaluation",
    "href": "project_card.html#evaluation",
    "title": "Project Card",
    "section": "Evaluation",
    "text": "Evaluation\nBased on the provided pipeline code, evaluation happens through: 1. Train/test split with configurable test size 2. Target drift detection between training and test sets using Evidently 3. Model performance tracking via MLflow 4. Production monitoring through FastAPI logging 5. Regular retraining evaluation",
    "crumbs": [
      "Read The Docs",
      "Cards",
      "Project Card"
    ]
  },
  {
    "objectID": "project_card.html#data",
    "href": "project_card.html#data",
    "title": "Project Card",
    "section": "Data",
    "text": "Data\n\nPrimary dataset: dataset_id_96.csv\nFeatures include:\n\nCredit history attributes (checking_status, credit_history, etc.)\nPersonal information (age, employment, etc.)\nLoan details (duration, credit_amount, etc.)\nGenerated features (X_1 through X_10)\n\nData Pipeline:\n\nRaw data ingestion via Kedro\nData quality checks\nPreprocessing including scaling and encoding\nFeature engineering\nTrain/test splitting",
    "crumbs": [
      "Read The Docs",
      "Cards",
      "Project Card"
    ]
  },
  {
    "objectID": "project_card.html#planroadmap",
    "href": "project_card.html#planroadmap",
    "title": "Project Card",
    "section": "Plan/Roadmap",
    "text": "Plan/Roadmap\n\nPhase 1 - Initial Development\n\nEnhance current data pipeline\nImplement additional data quality checks\nDevelop model monitoring dashboard\nComplete initial model training\n\nPhase 2 - Pilot\n\nDeploy to pilot branch\nGather user feedback\nRefine model based on real usage\nImplement A/B testing framework\n\nPhase 3 - Scale\n\nRoll out to additional branches\nImplement automated retraining pipeline\nEnhance monitoring and alerting\nDevelop fallback procedures",
    "crumbs": [
      "Read The Docs",
      "Cards",
      "Project Card"
    ]
  },
  {
    "objectID": "project_card.html#continuous-improvement",
    "href": "project_card.html#continuous-improvement",
    "title": "Project Card",
    "section": "Continuous Improvement",
    "text": "Continuous Improvement\n\nAutomated monitoring via:\n\nMLflow experiment tracking\nFastAPI request logging\nEvidently drift detection\n\nRegular Updates:\n\nModel retraining based on drift detection\nFeature importance analysis\nPerformance metric tracking\nUser feedback incorporation",
    "crumbs": [
      "Read The Docs",
      "Cards",
      "Project Card"
    ]
  },
  {
    "objectID": "project_card.html#resources",
    "href": "project_card.html#resources",
    "title": "Project Card",
    "section": "Resources",
    "text": "Resources\n\nHuman Resources\n\nData Science Team:\n\n1 ML Engineers (model development)\n1 Data Engineer (pipeline maintenance)\n1 MLOps Engineer (deployment/monitoring)\n\nProduct Team:\n\n1 Product Manager\n1 UX Designer\n1 Full-stack Developers\n\nDomain Experts:\n\n1 Credit Risk Officer\n1 Compliance Officer\n\n\n\n\nCompute Resources\n\nDevelopment:\n\nKedro pipeline execution environment\nMLflow tracking server\nDevelopment databases\n\nProduction:\n\nFastAPI server for model serving\nModel artifact storage\nMonitoring infrastructure\nLoad balancing for high availability\nBackup and disaster recovery systems\n\nStorage:\n\nSecure data warehouse for sensitive information\nModel registry\nLog storage\nBackup storage",
    "crumbs": [
      "Read The Docs",
      "Cards",
      "Project Card"
    ]
  },
  {
    "objectID": "reference/pipelines.data_processing.nodes.html",
    "href": "reference/pipelines.data_processing.nodes.html",
    "title": "pipelines.data_processing.nodes",
    "section": "",
    "text": "pipelines.data_processing.nodes\n\n\n\n\n\nName\nDescription\n\n\n\n\nidentify_categorical_columns\nIdentify categorical columns in the DataFrame.\n\n\nidentify_numerical_columns\nIdentify numerical columns in the DataFrame.\n\n\nload_data\nLoad the data from the CSV file.\n\n\npreprocess_data\nPreprocess the data by handling categorical variables, scaling numerical variables,\n\n\nrun_data_quality_checks\nRun data quality checks on the input data.\n\n\nsplit_data\nSplit the data into features and target.\n\n\n\n\n\npipelines.data_processing.nodes.identify_categorical_columns(df)\nIdentify categorical columns in the DataFrame.\nArgs: df: Input DataFrame\nReturns: List of categorical column names\n\n\n\npipelines.data_processing.nodes.identify_numerical_columns(df)\nIdentify numerical columns in the DataFrame.\nArgs: df: Input DataFrame\nReturns: List of numerical column names\n\n\n\npipelines.data_processing.nodes.load_data(data)\nLoad the data from the CSV file.\nArgs: data: Raw DataFrame loaded by Kedro\nReturns: Loaded DataFrame\n\n\n\npipelines.data_processing.nodes.preprocess_data(df)\nPreprocess the data by handling categorical variables, scaling numerical variables, and separating the target variable.\nArgs: df: Raw DataFrame\nReturns: Preprocessed DataFrame\n\n\n\npipelines.data_processing.nodes.run_data_quality_checks(df)\nRun data quality checks on the input data.\nArgs: df: Input DataFrame\nReturns: Dictionary containing key metrics\n\n\n\npipelines.data_processing.nodes.split_data(df, target_column='y')\nSplit the data into features and target.\nArgs: df: Preprocessed DataFrame target_column: Name of the target column\nReturns: Dictionary containing ‘features’ and ‘target’ as DataFrames",
    "crumbs": [
      "Read The Docs",
      "Data Processing",
      "pipelines.data_processing.nodes"
    ]
  },
  {
    "objectID": "reference/pipelines.data_processing.nodes.html#functions",
    "href": "reference/pipelines.data_processing.nodes.html#functions",
    "title": "pipelines.data_processing.nodes",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nidentify_categorical_columns\nIdentify categorical columns in the DataFrame.\n\n\nidentify_numerical_columns\nIdentify numerical columns in the DataFrame.\n\n\nload_data\nLoad the data from the CSV file.\n\n\npreprocess_data\nPreprocess the data by handling categorical variables, scaling numerical variables,\n\n\nrun_data_quality_checks\nRun data quality checks on the input data.\n\n\nsplit_data\nSplit the data into features and target.\n\n\n\n\n\npipelines.data_processing.nodes.identify_categorical_columns(df)\nIdentify categorical columns in the DataFrame.\nArgs: df: Input DataFrame\nReturns: List of categorical column names\n\n\n\npipelines.data_processing.nodes.identify_numerical_columns(df)\nIdentify numerical columns in the DataFrame.\nArgs: df: Input DataFrame\nReturns: List of numerical column names\n\n\n\npipelines.data_processing.nodes.load_data(data)\nLoad the data from the CSV file.\nArgs: data: Raw DataFrame loaded by Kedro\nReturns: Loaded DataFrame\n\n\n\npipelines.data_processing.nodes.preprocess_data(df)\nPreprocess the data by handling categorical variables, scaling numerical variables, and separating the target variable.\nArgs: df: Raw DataFrame\nReturns: Preprocessed DataFrame\n\n\n\npipelines.data_processing.nodes.run_data_quality_checks(df)\nRun data quality checks on the input data.\nArgs: df: Input DataFrame\nReturns: Dictionary containing key metrics\n\n\n\npipelines.data_processing.nodes.split_data(df, target_column='y')\nSplit the data into features and target.\nArgs: df: Preprocessed DataFrame target_column: Name of the target column\nReturns: Dictionary containing ‘features’ and ‘target’ as DataFrames",
    "crumbs": [
      "Read The Docs",
      "Data Processing",
      "pipelines.data_processing.nodes"
    ]
  },
  {
    "objectID": "reference/pipelines.data_science.pipeline.html",
    "href": "reference/pipelines.data_science.pipeline.html",
    "title": "pipelines.data_science.pipeline",
    "section": "",
    "text": "pipelines.data_science.pipeline\npipelines.data_science.pipeline",
    "crumbs": [
      "Read The Docs",
      "Pipelines",
      "pipelines.data_science.pipeline"
    ]
  },
  {
    "objectID": "reference/pipelines.data_science.nodes.html",
    "href": "reference/pipelines.data_science.nodes.html",
    "title": "pipelines.data_science.nodes",
    "section": "",
    "text": "pipelines.data_science.nodes\n\n\n\n\n\nName\nDescription\n\n\n\n\ndetect_target_drift\nDetects target drift between training and test sets.\n\n\nevaluate_model\nCalculates and logs the accuracy of the model.\n\n\nsplit_data\nSplits data into training and test sets.\n\n\ntrain_model\nTrains the random forest model.\n\n\n\n\n\npipelines.data_science.nodes.detect_target_drift(y_train, y_test)\nDetects target drift between training and test sets.\nArgs: y_train: Target variable from the training set (DataFrame) y_test: Target variable from the test set (DataFrame)\nRaises: ValueError: If significant target drift is detected\n\n\n\npipelines.data_science.nodes.evaluate_model(model, X_test, y_test)\nCalculates and logs the accuracy of the model.\n\n\n\npipelines.data_science.nodes.split_data(features, target, parameters)\nSplits data into training and test sets.\n\n\n\npipelines.data_science.nodes.train_model(X_train, y_train, parameters)\nTrains the random forest model.",
    "crumbs": [
      "Read The Docs",
      "Data Science",
      "pipelines.data_science.nodes"
    ]
  },
  {
    "objectID": "reference/pipelines.data_science.nodes.html#functions",
    "href": "reference/pipelines.data_science.nodes.html#functions",
    "title": "pipelines.data_science.nodes",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ndetect_target_drift\nDetects target drift between training and test sets.\n\n\nevaluate_model\nCalculates and logs the accuracy of the model.\n\n\nsplit_data\nSplits data into training and test sets.\n\n\ntrain_model\nTrains the random forest model.\n\n\n\n\n\npipelines.data_science.nodes.detect_target_drift(y_train, y_test)\nDetects target drift between training and test sets.\nArgs: y_train: Target variable from the training set (DataFrame) y_test: Target variable from the test set (DataFrame)\nRaises: ValueError: If significant target drift is detected\n\n\n\npipelines.data_science.nodes.evaluate_model(model, X_test, y_test)\nCalculates and logs the accuracy of the model.\n\n\n\npipelines.data_science.nodes.split_data(features, target, parameters)\nSplits data into training and test sets.\n\n\n\npipelines.data_science.nodes.train_model(X_train, y_train, parameters)\nTrains the random forest model.",
    "crumbs": [
      "Read The Docs",
      "Data Science",
      "pipelines.data_science.nodes"
    ]
  },
  {
    "objectID": "model_card.html",
    "href": "model_card.html",
    "title": "Model Card",
    "section": "",
    "text": "Model Description\n\n\nCode\nimport json\nfrom rich import print\nfrom pathlib import Path\n\nproject_dir = Path().absolute().parent\nmodel_card_path = project_dir / \"data\" / \"08_reporting\" / \"model-card\" / \"model_card.json\"\n\nwith open(model_card_path) as f:\n    model_card = json.load(f)\n    model_card = json.loads(model_card)\n\nprint(f\"\"\"• [bold]Model Type[/bold]: {model_card['model_type']}\"\"\")\n\n\n• Model Type: RandomForestClassifier\n\n\n\n\n\nIntended Use\n\n\nCode\nprint(\"\"\"• [bold]Primary Use[/bold]: Credit risk assessment\n• [bold]Intended Users[/bold]: Financial institutions, credit analysts\"\"\")\n\n\n• Primary Use: Credit risk assessment\n• Intended Users: Financial institutions, credit analysts\n\n\n\n\n\nModel Architecture\n\n\nCode\nprint(f\"\"\"• [bold]Base Estimators[/bold]: {model_card['model_parameters']['n_estimators']} decision trees\n• [bold]Max Depth[/bold]: {model_card['model_parameters']['max_depth']}\n• [bold]Criterion[/bold]: {model_card['model_parameters']['criterion']}\"\"\")\n\n\n• Base Estimators: 10 decision trees\n• Max Depth: 5\n• Criterion: gini\n\n\n\n\n\nModel Parameters\n\n\nCode\nparams_list = [f\"{i + 1}. {key}: {value}\" \n               for i, (key, value) in enumerate(model_card['model_parameters'].items())]\nprint(\"\\n\".join(params_list))\n\n\n1. bootstrap: True\n2. ccp_alpha: 0.0\n3. class_weight: None\n4. criterion: gini\n5. max_depth: 5\n6. max_features: sqrt\n7. max_leaf_nodes: None\n8. max_samples: None\n9. min_impurity_decrease: 0.0\n10. min_samples_leaf: 1\n11. min_samples_split: 2\n12. min_weight_fraction_leaf: 0.0\n13. monotonic_cst: None\n14. n_estimators: 10\n15. n_jobs: None\n16. oob_score: False\n17. random_state: None\n18. verbose: 0\n19. warm_start: False\n\n\n\n\n\nPerformance Metrics\n\n\nCode\nprint(f\"\"\"• [bold]Accuracy[/bold]: {model_card['evaluation_metrics']['accuracy']:.2f}\n• [bold]Precision[/bold]: {model_card['evaluation_metrics']['precision']:.2f}\n• [bold]Recall[/bold]: {model_card['evaluation_metrics']['recall']:.2f}\n• [bold]F1 Score[/bold]: {model_card['evaluation_metrics']['f1']:.2f}\"\"\")\n\n\n• Accuracy: 0.78\n• Precision: 0.64\n• Recall: 1.00\n• F1 Score: 0.78\n\n\n\n\n\nTraining Data\n\n\nCode\nprint(\"\"\"• [bold]Dataset[/bold]: dataset_id_96\n• [bold]Splitting Method[/bold]: Random split (80% training, 20% testing)\n• [bold]Preprocessing[/bold]: Standard scaling for numerical features, one-hot encoding for\n  categorical features\"\"\")\n\n\n• Dataset: dataset_id_96\n• Splitting Method: Random split (80% training, 20% testing)\n• Preprocessing: Standard scaling for numerical features, one-hot encoding for\n  categorical features\n\n\n\n\n\nEthical Considerations\n\n\nCode\nprint(\"\"\"• Decisions based on this model's output should be explainable and challengeable.\n• The model should be used in compliance with relevant financial regulations and data\n  protection laws.\"\"\")\n\n\n• Decisions based on this model's output should be explainable and challengeable.\n• The model should be used in compliance with relevant financial regulations and data\n  protection laws.\n\n\n\n\n\nCaveats and Recommendations\n\n\nCode\nprint(\"\"\"• The model's performance may vary for different subgroups. It's recommended to evaluate\n  the model's fairness across various demographic groups.\n• Regular retraining is advised to ensure the model remains accurate as financial trends\n  evolve.\n• The model should be used in conjunction with other risk assessment methods and human\n  judgment.\"\"\")\n\n\n• The model's performance may vary for different subgroups. It's recommended to evaluate\n  the model's fairness across various demographic groups.\n• Regular retraining is advised to ensure the model remains accurate as financial trends\n  evolve.\n• The model should be used in conjunction with other risk assessment methods and human\n  judgment.",
    "crumbs": [
      "Read The Docs",
      "Cards",
      "Model Card"
    ]
  },
  {
    "objectID": "data_card.html",
    "href": "data_card.html",
    "title": "Data Card",
    "section": "",
    "text": "Dataset Description\n\n\nCode\nimport json\nfrom rich import print\nfrom pathlib import Path\n\nname = \"dataset_id_96\"\ndescription = \"Credit risk assessment dataset\"\ncreation_date = \"Unknown\"\nversion = \"1.0\"\n\nprint(f\"\"\"• [bold]Name[/bold]: {name}\n• [bold]Description[/bold]: {description}\n• [bold]Version[/bold]: {version}\"\"\")\n\n\n• Name: dataset_id_96\n• Description: Credit risk assessment dataset\n• Version: 1.0\n\n\n\n\n\nDataset Characteristics\n\n\nCode\nproject_dir = Path().absolute().parent\ndata_card_path = project_dir / \"data\" / \"08_reporting\" / \"data-card\" / \"data_card.json\"\n\nwith open(data_card_path) as f:\n    data_card = json.load(f)\n    data_card = json.loads(data_card)\nprint(f\"\"\"• [bold]Number of Instances[/bold]: {data_card['number_of_rows']}\n• [bold]Number of Features[/bold]: {data_card['number_of_features']}\n• [bold]Target Variable[/bold]: y (boolean)\"\"\")\n\n\n• Number of Instances: 90\n• Number of Features: 32\n• Target Variable: y (boolean)\n\n\n\n\n\nFeatures\n\n\nCode\nfeatures_list = [f\"{i + 1}. {data_card['feature_names'][i]}\" \n                 for i in range(len(data_card[\"feature_names\"]))]\nprint(\"\\n\".join(features_list))\n\n\n1. checking_status\n2. duration\n3. credit_history\n4. purpose\n5. credit_amount\n6. savings_status\n7. employment\n8. installment_commitment\n9. personal_status\n10. other_parties\n11. residence_since\n12. property_magnitude\n13. age\n14. other_payment_plans\n15. housing\n16. existing_credits\n17. job\n18. num_dependents\n19. own_telephone\n20. foreign_worker\n21. health_status\n22. X_1\n23. X_2\n24. X_3\n25. X_4\n26. X_5\n27. X_6\n28. X_7\n29. X_8\n30. X_9\n31. X_10\n32. y\n\n\n\n\n\nData Collection\n\n\nCode\nmethod = \"Unknown\"\nprint(f\"• [bold]Method[/bold]: {method}\")\n\n\n• Method: Unknown\n\n\n\n\n\nIntended Use\n\n\nCode\nprint(\"\"\"This dataset can be used to train machine learning models to predict the likelihood of\ncredit default.\n      \"\"\")\n\n\nThis dataset can be used to train machine learning models to predict the likelihood of\ncredit default.\n      \n\n\n\n\n\nEthical Considerations\n\n\nCode\nprint(\"\"\"• Ensure fair and unbiased use of the data, particularly regarding protected attributes \n  like personal status.\n• Be cautious of potential biases in the original data collection process.\n• Consider the implications of using this data for decision-making in financial contexts.\"\"\")\n\n\n• Ensure fair and unbiased use of the data, particularly regarding protected attributes \n  like personal status.\n• Be cautious of potential biases in the original data collection process.\n• Consider the implications of using this data for decision-making in financial contexts.\n\n\n\n\n\nKnown Limitations\n\n\nCode\nprint(f\"\"\"• The dataset is relatively small ({data_card['number_of_rows']} instances), which may limit its representativeness.\n• Some categorical variables may have imbalanced categories.\n• The additional numerical features (X_1 to X_10) lack clear descriptions of what they\n  represent.\n      \"\"\")\n\n\n• The dataset is relatively small (90 instances), which may limit its representativeness.\n• Some categorical variables may have imbalanced categories.\n• The additional numerical features (X_1 to X_10) lack clear descriptions of what they\n  represent.",
    "crumbs": [
      "Read The Docs",
      "Cards",
      "Data Card"
    ]
  },
  {
    "objectID": "reference/index.html",
    "href": "reference/index.html",
    "title": "Function reference",
    "section": "",
    "text": "tathagata-ai-839"
  },
  {
    "objectID": "reference/index.html#tathagata_ai_839",
    "href": "reference/index.html#tathagata_ai_839",
    "title": "Function reference",
    "section": "",
    "text": "tathagata-ai-839"
  },
  {
    "objectID": "reference/pipelines.data_processing.pipeline.html",
    "href": "reference/pipelines.data_processing.pipeline.html",
    "title": "pipelines.data_processing.pipeline",
    "section": "",
    "text": "pipelines.data_processing.pipeline\npipelines.data_processing.pipeline",
    "crumbs": [
      "Read The Docs",
      "Pipelines",
      "pipelines.data_processing.pipeline"
    ]
  },
  {
    "objectID": "docs-quarto.html",
    "href": "docs-quarto.html",
    "title": "tathagata_ai_839 Documentation",
    "section": "",
    "text": "Welcome to the documentation for tathagata_ai_839."
  },
  {
    "objectID": "docs-quarto.html#api-reference",
    "href": "docs-quarto.html#api-reference",
    "title": "tathagata_ai_839 Documentation",
    "section": "API Reference",
    "text": "API Reference\nThe API reference for this project has been automatically generated. You can find the documentation for different modules here:\n\nData Processing Nodes\nData Science Nodes\nData Processing Pipeline\nData Science Pipeline\nDataset Card\nModel Card\nProject Card"
  }
]